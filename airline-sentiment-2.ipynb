{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "def get_selected_models(names):\n",
    "  \"\"\"\n",
    "  Returns selected models for ML processing\n",
    "\n",
    "  Args:\n",
    "      names (_type_):List\n",
    "\n",
    "  Returns:\n",
    "      List of models\n",
    "  \"\"\"\n",
    "  models = {\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"GPC\": GaussianProcessClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"LR\":LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"GBC\":GradientBoostingClassifier(),\n",
    "    \"RFC\":RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier()\n",
    "  }\n",
    "  \n",
    "  return [models[model] for model in names]\n",
    "\n",
    "def svm_tune_grid_search(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    model = SVC()\n",
    "    \n",
    "    param_grid = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "    \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Test accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    return grid_search\n",
    "  \n",
    "def sentiment_score(review, tokenizer, model):\n",
    "  tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "  result = model(tokens)\n",
    "  return int(torch.argmax(result.logits)) +1\n",
    "\n",
    "def evaluate_model(X, y, model):\n",
    "  # define evaluation procedure\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  \n",
    "  metric = make_scorer(accuracy_score)\n",
    "  # evaluate model\n",
    "  scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  return scores\n",
    "\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        # Evaluate the model\n",
    "        scores = evaluate_model(X, y, model)\n",
    "        # summarize and store\n",
    "        print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "def logistic_regression_tune_cv(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    param_grid = {\n",
    "        'solver': ['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "        'C': [0.1, 0.2, 0.4, 0.5, 1, 2, 4, 5, 10, 20, 50, 100, 400]\n",
    "    }\n",
    "    model = LogisticRegression(class_weight='balanced', penalty='l2', max_iter=2000)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "    \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Test accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/test/Downloads/Tweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>569970938525016065</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tbird12lv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united by the time I finally get to Dallas I ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 13:23:55 -0800</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Mountain Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>569970599377788928</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cristobalwong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united I'm trying to get to my final destinat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 13:22:35 -0800</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>569970225443172353</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsmetsforme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united that guy really has no customer servic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 13:21:05 -0800</td>\n",
       "      <td>mets hell</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>569969999961391105</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>swampynomo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united he has no priority and Iove it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 13:20:12 -0800</td>\n",
       "      <td>NJ/NYC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>569969952654028800</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>herma48852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Pleased to be a Premier Platinum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 13:20:00 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0    570306133677760513           neutral                        1.0000   \n",
       "1    570301130888122368          positive                        0.3486   \n",
       "2    570301083672813571           neutral                        0.6837   \n",
       "3    570301031407624196          negative                        1.0000   \n",
       "4    570300817074462722          negative                        1.0000   \n",
       "..                  ...               ...                           ...   \n",
       "995  569970938525016065          negative                        1.0000   \n",
       "996  569970599377788928          negative                        1.0000   \n",
       "997  569970225443172353          negative                        1.0000   \n",
       "998  569969999961391105          positive                        0.6915   \n",
       "999  569969952654028800          positive                        1.0000   \n",
       "\n",
       "             negativereason  negativereason_confidence         airline  \\\n",
       "0                       NaN                        NaN  Virgin America   \n",
       "1                       NaN                     0.0000  Virgin America   \n",
       "2                       NaN                        NaN  Virgin America   \n",
       "3                Bad Flight                     0.7033  Virgin America   \n",
       "4                Can't Tell                     1.0000  Virgin America   \n",
       "..                      ...                        ...             ...   \n",
       "995             Late Flight                     0.7065          United   \n",
       "996             Late Flight                     1.0000          United   \n",
       "997  Customer Service Issue                     0.6667          United   \n",
       "998                     NaN                        NaN          United   \n",
       "999                     NaN                        NaN          United   \n",
       "\n",
       "     airline_sentiment_gold           name  negativereason_gold  \\\n",
       "0                       NaN        cairdin                  NaN   \n",
       "1                       NaN       jnardino                  NaN   \n",
       "2                       NaN     yvonnalynn                  NaN   \n",
       "3                       NaN       jnardino                  NaN   \n",
       "4                       NaN       jnardino                  NaN   \n",
       "..                      ...            ...                  ...   \n",
       "995                     NaN      tbird12lv                  NaN   \n",
       "996                     NaN  cristobalwong                  NaN   \n",
       "997                     NaN   itsmetsforme                  NaN   \n",
       "998                     NaN     swampynomo                  NaN   \n",
       "999                     NaN     herma48852                  NaN   \n",
       "\n",
       "     retweet_count                                               text  \\\n",
       "0                0                @VirginAmerica What @dhepburn said.   \n",
       "1                0  @VirginAmerica plus you've added commercials t...   \n",
       "2                0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3                0  @VirginAmerica it's really aggressive to blast...   \n",
       "4                0  @VirginAmerica and it's a really big bad thing...   \n",
       "..             ...                                                ...   \n",
       "995              0  @united by the time I finally get to Dallas I ...   \n",
       "996              0  @united I'm trying to get to my final destinat...   \n",
       "997              0  @united that guy really has no customer servic...   \n",
       "998              0             @united he has no priority and Iove it   \n",
       "999              0           @united Pleased to be a Premier Platinum   \n",
       "\n",
       "    tweet_coord              tweet_created          tweet_location  \\\n",
       "0           NaN  2015-02-24 11:35:52 -0800                     NaN   \n",
       "1           NaN  2015-02-24 11:15:59 -0800                     NaN   \n",
       "2           NaN  2015-02-24 11:15:48 -0800               Lets Play   \n",
       "3           NaN  2015-02-24 11:15:36 -0800                     NaN   \n",
       "4           NaN  2015-02-24 11:14:45 -0800                     NaN   \n",
       "..          ...                        ...                     ...   \n",
       "995         NaN  2015-02-23 13:23:55 -0800                Colorado   \n",
       "996         NaN  2015-02-23 13:22:35 -0800  San Francisco Bay Area   \n",
       "997         NaN  2015-02-23 13:21:05 -0800               mets hell   \n",
       "998         NaN  2015-02-23 13:20:12 -0800                  NJ/NYC   \n",
       "999         NaN  2015-02-23 13:20:00 -0800                     NaN   \n",
       "\n",
       "                   user_timezone  \n",
       "0     Eastern Time (US & Canada)  \n",
       "1     Pacific Time (US & Canada)  \n",
       "2     Central Time (US & Canada)  \n",
       "3     Pacific Time (US & Canada)  \n",
       "4     Pacific Time (US & Canada)  \n",
       "..                           ...  \n",
       "995  Mountain Time (US & Canada)  \n",
       "996                          NaN  \n",
       "997                          NaN  \n",
       "998   Eastern Time (US & Canada)  \n",
       "999                          NaN  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.read_csv(filename, nrows= 1000)\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>@united by the time I finally get to Dallas I ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@united I'm trying to get to my final destinat...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>@united that guy really has no customer servic...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@united he has no priority and Iove it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@united Pleased to be a Premier Platinum</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text airline_sentiment\n",
       "0                  @VirginAmerica What @dhepburn said.           neutral\n",
       "1    @VirginAmerica plus you've added commercials t...          positive\n",
       "2    @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3    @VirginAmerica it's really aggressive to blast...          negative\n",
       "4    @VirginAmerica and it's a really big bad thing...          negative\n",
       "..                                                 ...               ...\n",
       "995  @united by the time I finally get to Dallas I ...          negative\n",
       "996  @united I'm trying to get to my final destinat...          negative\n",
       "997  @united that guy really has no customer servic...          negative\n",
       "998             @united he has no priority and Iove it          positive\n",
       "999           @united Pleased to be a Premier Platinum          positive\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_[[\"text\",'airline_sentiment']].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mapping = {\"positive\":1, 'neutral':0, \"negative\":2}\n",
    "\n",
    "df['target'] = df['airline_sentiment'].map(text_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>@united by the time I finally get to Dallas I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@united I'm trying to get to my final destinat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>@united that guy really has no customer servic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@united he has no priority and Iove it</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@united Pleased to be a Premier Platinum</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text airline_sentiment  \\\n",
       "0                  @VirginAmerica What @dhepburn said.           neutral   \n",
       "1    @VirginAmerica plus you've added commercials t...          positive   \n",
       "2    @VirginAmerica I didn't today... Must mean I n...           neutral   \n",
       "3    @VirginAmerica it's really aggressive to blast...          negative   \n",
       "4    @VirginAmerica and it's a really big bad thing...          negative   \n",
       "..                                                 ...               ...   \n",
       "995  @united by the time I finally get to Dallas I ...          negative   \n",
       "996  @united I'm trying to get to my final destinat...          negative   \n",
       "997  @united that guy really has no customer servic...          negative   \n",
       "998             @united he has no priority and Iove it          positive   \n",
       "999           @united Pleased to be a Premier Platinum          positive   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         2  \n",
       "4         2  \n",
       "..      ...  \n",
       "995       2  \n",
       "996       2  \n",
       "997       2  \n",
       "998       1  \n",
       "999       1  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"berta_model\"] = df[\"text\"].apply(lambda review: sentiment_score(review, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>berta_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>@united by the time I finally get to Dallas I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@united I'm trying to get to my final destinat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>@united that guy really has no customer servic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@united he has no priority and Iove it</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@united Pleased to be a Premier Platinum</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text airline_sentiment  \\\n",
       "0                  @VirginAmerica What @dhepburn said.           neutral   \n",
       "1    @VirginAmerica plus you've added commercials t...          positive   \n",
       "2    @VirginAmerica I didn't today... Must mean I n...           neutral   \n",
       "3    @VirginAmerica it's really aggressive to blast...          negative   \n",
       "4    @VirginAmerica and it's a really big bad thing...          negative   \n",
       "..                                                 ...               ...   \n",
       "995  @united by the time I finally get to Dallas I ...          negative   \n",
       "996  @united I'm trying to get to my final destinat...          negative   \n",
       "997  @united that guy really has no customer servic...          negative   \n",
       "998             @united he has no priority and Iove it          positive   \n",
       "999           @united Pleased to be a Premier Platinum          positive   \n",
       "\n",
       "     target  berta_model  \n",
       "0         0            5  \n",
       "1         1            5  \n",
       "2         0            1  \n",
       "3         2            4  \n",
       "4         2            1  \n",
       "..      ...          ...  \n",
       "995       2            2  \n",
       "996       2            1  \n",
       "997       2            1  \n",
       "998       1            1  \n",
       "999       1            5  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='berta_model'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"berta_model\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "berta_model\n",
       "1    556\n",
       "5    310\n",
       "3     68\n",
       "4     36\n",
       "2     30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"berta_model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "2    514\n",
       "0    272\n",
       "1    214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying TF-IDF to the specified column of the DataFrame\n",
    "tfidf_matrix = tfidf.fit_transform(df['text'])\n",
    "\n",
    "# Converting the TF-IDF matrix to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Concatenate the new DataFrame with the original DataFrame (optional)\n",
    "# Make sure indexes align if not, reset index before concatenation.\n",
    "df = pd.concat([df.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>berta_model</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0016</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yul</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yvr</th>\n",
       "      <th>zambia</th>\n",
       "      <th>zcbjyo6lsn</th>\n",
       "      <th>zcc82u</th>\n",
       "      <th>zero</th>\n",
       "      <th>zfqmpgxvs6</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>@united by the time I finally get to Dallas I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@united I'm trying to get to my final destinat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>@united that guy really has no customer servic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@united he has no priority and Iove it</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@united Pleased to be a Premier Platinum</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text airline_sentiment  \\\n",
       "0                  @VirginAmerica What @dhepburn said.           neutral   \n",
       "1    @VirginAmerica plus you've added commercials t...          positive   \n",
       "2    @VirginAmerica I didn't today... Must mean I n...           neutral   \n",
       "3    @VirginAmerica it's really aggressive to blast...          negative   \n",
       "4    @VirginAmerica and it's a really big bad thing...          negative   \n",
       "..                                                 ...               ...   \n",
       "995  @united by the time I finally get to Dallas I ...          negative   \n",
       "996  @united I'm trying to get to my final destinat...          negative   \n",
       "997  @united that guy really has no customer servic...          negative   \n",
       "998             @united he has no priority and Iove it          positive   \n",
       "999           @united Pleased to be a Premier Platinum          positive   \n",
       "\n",
       "     target  berta_model   00  000  0016   10  100   11  ...  yrs  yul  yummy  \\\n",
       "0         0            5  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "1         1            5  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "2         0            1  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "3         2            4  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "4         2            1  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "..      ...          ...  ...  ...   ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "995       2            2  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "996       2            1  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "997       2            1  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "998       1            1  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "999       1            5  0.0  0.0   0.0  0.0  0.0  0.0  ...  0.0  0.0    0.0   \n",
       "\n",
       "     yvr  zambia  zcbjyo6lsn  zcc82u  zero  zfqmpgxvs6  zone  \n",
       "0    0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "1    0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "2    0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "3    0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "4    0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "..   ...     ...         ...     ...   ...         ...   ...  \n",
       "995  0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "996  0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "997  0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "998  0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "999  0.0     0.0         0.0     0.0   0.0         0.0   0.0  \n",
       "\n",
       "[1000 rows x 2004 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"text\", \"airline_sentiment\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.drop('target', axis=1), df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RFC 0.700 (0.032)\n",
      ">DTC 0.614 (0.055)\n",
      ">XGB 0.686 (0.037)\n",
      ">LR 0.707 (0.037)\n",
      ">SVC 0.656 (0.023)\n",
      ">GBC 0.693 (0.042)\n"
     ]
    }
   ],
   "source": [
    "names = [\"RFC\", \"DTC\", \"XGB\", \"LR\", \"SVC\", \"GBC\"]\n",
    "models = get_selected_models(names)\n",
    "testing_selected_models(names, models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/test/miniforge3/envs/machine-learning-env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/test/miniforge3/envs/machine-learning-env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'solver': 'newton-cg'}\n",
      "Best cross-validation score: 0.729\n",
      "Test accuracy: 0.660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                          max_iter=2000),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.2, 0.4, 0.5, 1, 2, 4, 5, 10, 20, 50, 100,\n",
       "                               400],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                          max_iter=2000),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.2, 0.4, 0.5, 1, 2, 4, 5, 10, 20, 50, 100,\n",
       "                               400],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=2000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=2000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=2000),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.2, 0.4, 0.5, 1, 2, 4, 5, 10, 20, 50, 100,\n",
       "                               400],\n",
       "                         'solver': ['newton-cg', 'sag', 'saga', 'lbfgs']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_tune_cv(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'kernel': 'linear'}\n",
      "Best cross-validation score: 0.730\n",
      "Test accuracy: 0.683\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tune_grid_search(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Split the dataset\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     56\u001b[0m functions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     57\u001b[0m   create_model_dropout,\n\u001b[1;32m     58\u001b[0m   create_model_regularizerL1,\n\u001b[1;32m     59\u001b[0m   create_model_regularizerl2\n\u001b[1;32m     60\u001b[0m ]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Define the optimizers to iterate over\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.regularizers import l2, l1\n",
    "# MLP\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_keras_classifier(function, optimizer, idx, param):\n",
    "    if idx == 0:\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            build_fn=lambda: function(input_dim=X_train.shape[1], optimizer=optimizer)\n",
    "            , epochs=100, \n",
    "            batch_size=64, \n",
    "            verbose=0\n",
    "            )\n",
    "    elif idx ==1:\n",
    "        model = KerasClassifier(\n",
    "            build_fn=lambda: function(input_dim=X_train.shape[1], optimizer=optimizer, param=param)\n",
    "            , epochs=100, \n",
    "            batch_size=64, \n",
    "            verbose=0\n",
    "            )\n",
    "        \n",
    "    else:\n",
    "        model = KerasClassifier(\n",
    "            build_fn=lambda: function(input_dim=X_train.shape[1], optimizer=optimizer, param=param)\n",
    "            , epochs=100, \n",
    "            batch_size=64, \n",
    "            verbose=0\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def create_model_dropout(input_dim, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "def create_model_regularizerl2(input_dim, optimizer=\"adam\",param= 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu', kernel_regularizer=l2(param) ))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "def create_model_regularizerL1(input_dim, optimizer=\"adam\",param= 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu', activity_regularizer=l1(param) ))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "functions = [\n",
    "  create_model_dropout,\n",
    "  create_model_regularizerL1,\n",
    "  create_model_regularizerl2\n",
    "]\n",
    "# Define the optimizers to iterate over\n",
    "optimizers = [\n",
    "    Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
    "    RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07),\n",
    "    SGD(lr=0.01, momentum=0.9), \n",
    "    SGD(lr=0.001, momentum=0.9),\n",
    "    ]\n",
    "optimizer_names = ['Adam', \"RmsProp\", \"SGD:0.01\", \"SGD:0.001\"]\n",
    "function_names = [\"Dropout\", \"L1\", \"L2\"]\n",
    "values = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "model_performance = []\n",
    "for index, function in enumerate(functions):\n",
    "    name = function_names[index]\n",
    "    for idx, optimizer in enumerate(optimizers):\n",
    "        optimizer_name = optimizer_names[idx]\n",
    "        value = values[idx]\n",
    "        model = create_keras_classifier(function, optimizer, index, value)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        model_performance.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Optimizer\": optimizer_name,\n",
    "            \"Value\": value\n",
    "        })\n",
    "model_df = pd.DataFrame(model_performance)\n",
    "end_result = model_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "end_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
